{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import pprint\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load NLTK and Test Dataset</font>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Treebank tagged sentences using **universal** tagset\n",
    "\n",
    "`VERB - verbs (all tenses and modes)\n",
    "NOUN - nouns (common and proper)\n",
    "PRON - pronouns \n",
    "ADJ - adjectives\n",
    "ADV - adverbs\n",
    "ADP - adpositions (prepositions and postpositions)\n",
    "CONJ - conjunctions\n",
    "DET - determiners\n",
    "NUM - cardinal numbers\n",
    "PRT - particles or other function words\n",
    "X - other: foreign words, typos, abbreviations\n",
    ". - punctuation\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Pierre', 'NOUN'), ('Vinken', 'NOUN'), (',', '.'), ('61', 'NUM'), ('years', 'NOUN'), ('old', 'ADJ'), (',', '.'), ('will', 'VERB'), ('join', 'VERB'), ('the', 'DET'), ('board', 'NOUN'), ('as', 'ADP'), ('a', 'DET'), ('nonexecutive', 'ADJ'), ('director', 'NOUN'), ('Nov.', 'NOUN'), ('29', 'NUM'), ('.', '.')], [('Mr.', 'NOUN'), ('Vinken', 'NOUN'), ('is', 'VERB'), ('chairman', 'NOUN'), ('of', 'ADP'), ('Elsevier', 'NOUN'), ('N.V.', 'NOUN'), (',', '.'), ('the', 'DET'), ('Dutch', 'NOUN'), ('publishing', 'VERB'), ('group', 'NOUN'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "# observe a few tagged sentences from the corpora\n",
    "print(nltk_data[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Android is a mobile operating system developed by Google.\\nAndroid has been the best-selling OS worldwide on smartphones since 2011 and on tablets since 2013.\\nGoogle and Twitter made a deal in 2015 that gave Google access to Twitter's firehose.\\nTwitter is an online news and social networking service on which users post and interact with messages known as tweets.\\nBefore entering politics, Donald Trump was a domineering businessman and a television personality.\\nThe 2018 FIFA World Cup is the 21st FIFA World Cup, an international football tournament contested once every four years.\\nThis is the first World Cup to be held in Eastern Europe and the 11th time that it has been held in Europe.\\nShow me the cheapest round trips from Dallas to Atlanta\\nI would like to see flights from Denver to Philadelphia.\\nShow me the price of the flights leaving Atlanta at about 3 in the afternoon and arriving in San Francisco.\\nNASA invited social media users to experience the launch of ICESAT-2 Satellite.\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_object = open(r\"test-sentences.txt\",\"r\", encoding=\"latin1\")\n",
    "test_data = file_object.read()\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of words in the test dataset\n",
    "test_data_words = nltk.word_tokenize(test_data)\n",
    "len(test_data_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tagging Test Dataset With NLTK POS Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'words with tagged with ADJ'\n",
      "['best-selling',\n",
      " 'cheapest',\n",
      " 'domineering',\n",
      " 'first',\n",
      " 'international',\n",
      " 'mobile',\n",
      " 'online',\n",
      " 'social']\n"
     ]
    }
   ],
   "source": [
    "test_tagged_words = {}\n",
    "test_tagged = nltk.pos_tag(test_data_words, tagset='universal')\n",
    "universal_tagset = [\n",
    "    'VERB', 'NOUN', 'PRON', 'ADJ', 'ADV', \n",
    "    'ADP', 'CONJ', 'DET', 'NUM', 'PRT', 'X', '.'\n",
    "]\n",
    "\n",
    "for utag in universal_tagset:\n",
    "    test_tagged_words[utag] = sorted(\n",
    "        set([word for (word, tag) in test_tagged if tag == utag]))\n",
    "\n",
    "i = random.randrange(len(universal_tagset))\n",
    "\n",
    "pprint.pprint('words with tagged with {}'.format(universal_tagset[i]))\n",
    "pprint.pprint(test_tagged_words[universal_tagset[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Split data into train and validation datasets\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences in train dataset : 3718\n",
      "Number of sentences in validation dataset : 196\n"
     ]
    }
   ],
   "source": [
    "train_set, validation_set = train_test_split(nltk_data,\n",
    "                                             test_size=0.05,\n",
    "                                             random_state=1234)\n",
    "\n",
    "print('Number of sentences in train dataset : {0}'.format(len(train_set)))\n",
    "print('Number of sentences in validation dataset : {0}'.format(len(validation_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tagged_words = [tup for sent in train_set for tup in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of words in the training set : 95799\n",
      "total number of unique words in the training set: 12073\n"
     ]
    }
   ],
   "source": [
    "tokens = [pair[0] for pair in train_tagged_words]\n",
    "print('total number of words in the training set : {0}'.format(len(tokens)))\n",
    "\n",
    "vocabulary = set(tokens)\n",
    "print('total number of unique words in the training set: {0}'.format(len(vocabulary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of tags in the universal tagset : 12\n",
      "['.', 'ADJ', 'ADP', 'ADV', 'CONJ', 'DET', 'NOUN', 'NUM', 'PRON', 'PRT', 'VERB', 'X']\n"
     ]
    }
   ],
   "source": [
    "all_tags = [pair[1] for pair in train_tagged_words]\n",
    "unique_tags = sorted(set(all_tags))\n",
    "\n",
    "print('number of tags in the universal tagset : {}'.format(len(unique_tags)))\n",
    "print(unique_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Helper Functions\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store number of times a tag 'T' appears in the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'.': 11130, 'ADJ': 6063, 'ADP': 9387, 'ADV': 3052, 'CONJ': 2144, 'DET': 8269, 'NOUN': 27471, 'NUM': 3364, 'PRON': 2619, 'PRT': 3070, 'VERB': 12910, 'X': 6320}\n"
     ]
    }
   ],
   "source": [
    "tag_count_dict = dict()\n",
    "\n",
    "for utag in unique_tags:\n",
    "    tag_list = [pair[1] for pair in train_tagged_words if pair[1] == utag]\n",
    "    tag_count_dict[utag] = len(tag_list)\n",
    "    \n",
    "print(tag_count_dict)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of Unknown Words in Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unknown words in validation data set : 335\n"
     ]
    }
   ],
   "source": [
    "val_data_unknown_words = [word for sent in validation_set for (word, tag) in sent if word not in vocabulary]\n",
    "print('number of unknown words in validation data set : {0}'.format(len(set(val_data_unknown_words))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of Unknown Words in Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unknown words in test data set : 28\n"
     ]
    }
   ],
   "source": [
    "test_data_unknown_words = [word for word in test_data_words if word not in vocabulary]\n",
    "print('number of unknown words in test data set : {0}'.format(len(set(test_data_unknown_words))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Number of Words correctly tagged in Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_test_dataset_accuracy(tagged_test_set):\n",
    "    total_words = 0\n",
    "    correct_tagged_words = 0\n",
    "\n",
    "    for word, tag in tagged_test_set:\n",
    "        try:\n",
    "            list_for_tag = test_tagged_words[tag]\n",
    "        except KeyError:\n",
    "            list_for_tag = []\n",
    "\n",
    "        total_words += 1\n",
    "\n",
    "        if word in list_for_tag:\n",
    "            correct_tagged_words += 1\n",
    "\n",
    "    print('total words - {0}. correctly tagged words - {1}. accuracy - {2}'.\n",
    "          format(total_words, correct_tagged_words,\n",
    "                 correct_tagged_words / total_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
